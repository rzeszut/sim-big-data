\section{Analiza literatury}
\label{sec:analiza_literatury}

\subsection{Metody}
\label{sub:metody}
Big Data wymaga wyjątkowych technologii do efektywnego przetwarzania olbrzymich ilości danych w rozsądnym czasie. W 2011 roku firma {McKinsley} w swoim raporcie \cite{McKinsey2011} zaproponowała użycie do analizy Big Data takich technik jak testy A/B, crowdsourcing, eksploracja danych, algorytmy genetyczne etc.

\subsubsection{A/B testing}
\label{sub:a/b_testing}
\textbf{Testy A/B} jest to metoda badawcza służąca do wybrania lepszego rozwiązania. W założeniu osoba przeprowadzająca test posiada dwie wersje danego elementu i metrykę określającą optymalność. Aby wybrać lepsze rozwiązanie, obie wersje poddawane są temu samemu eksperymentowi. Na końcu mierzony jest wcześniej ustalony wskaźnik jakości i wybierane jest lepsze rozwiązanie \cite{paras10}.

\subsubsection{Association rule learning}
\label{sub:association_rule_learning}
\textbf{Association rule learning} jest to popularna i dobrze zbadana metoda szukania relacji pomiędzy zmiennymi w dużych bazach danych \cite{tan2005introduction}.

\subsubsection{Crowdsourcing}
\label{sub:crowdsourcing}
Termin \textbf{crowdsourcing} został po raz pierwszy zdefiniowany i użyty przez dziennikarza magazynu Wired Jeffa Howe’a \cite{Howe2006}. Odnosi się on do procesu, w którym wszelkie potrzebne moduły, serwisy, pomysły czy materiały pozyskiwane są od dużej grupy ludzi (zwłaszcza od społeczności online) w formie outsourcingu. Jest to metoda zastępująca tradycyjnych pracowników bądź dostawców. Proces ten jest często używany do podziału żmudnej pracy lub w celu pozyskiwania funduszy na finansowanie nowych firm i organizacji charytatywnych \cite{Howe2006}.

Crowdsourcing łączy wysiłki wielu wolontariuszy i pracowników tymczasowych. Każdy z uczestników wnosi do projektu niewielki nakład pracy, co przy dużej liczbie ochotników powoduje osiągnięcie określonego celu.

Crowdsourcing różni się od outsourcingu tym, że wolontariuszem może zostać każdy, a nie tylko wybrana grupa ludzi.

\subsubsection{Eksploracja danych}
\label{sub:eksploracja_danych}
\textbf{Eksploracja danych} (\textit{ang. data mining}) jest jedną z metod analizy danych. Jest to ,,nauka zajmująca się wydobywaniem informacji z dużych zbiorów danych lub baz danych'' \cite{Hand01}. Metoda ta wykorzystuje prędkość przetwarzania danych przez komputery do znalezienia prawidłowości w danych, które są zgromadzone w pewnym rodzaju bazy danych, zorganizowanej pod kątem pewnej części rzeczywistości (\textit{hurtownia danych}). 

Eksplorację danych można rozwiązać na wiele sposobów. Mogą to być:
\begin{enumerate}
  \item wizualizaje na wykresach
  \item metody statystyczne
  \item zbiory przybliżone
  \item logika rozmyta
  \item metody ewolucyjne
  \item metody uczenia maszynowego
  \item sieci neuronowe \ldots
\end{enumerate}

\subsubsection{Data Integration}
\label{sub:data_integration}
\textbf{Data fusion} i \textbf{data integration} to zbiór technik do integracji i analizy danych pochodzących z różnych źródeł \cite{lenzerini02}. Przykładowym wykorzystaniem tych technik jest połączenie danych z serwisów społecznościowych (np. Twitter, Facebook) z danymi finansowymi, aby określić stopień powodzenia kampanii reklamowej.

\subsubsection{Algorytmy genetyczne}
\label{sub:algorytmy_genetyczne}
Algorytm genetyczny jest to rodzaj algorytmu przeszukujący możliwe rozwiązania w celu znalezienia najoptymalniejszych lub najlepszych. Za ich twórcę uważa się John Henry Hollanda, który prowadził swoje badania zainspirowany ewolucją biologiczną.

Jest on zaliczany do grupy algorytmów ewolucyjnych, a więc jest jedną z technik eksploracji danych opisanej w sekcji \ref{sub:eksploracja_danych}.

Poniższy schemat blokowy przedstawia zasadę działania tego algorytmu:
\begin{figure}[h]
\centerline{\includegraphics[scale=0.5]{obrazki/algorytm_genetyczny.png}}
\caption{Schemat działania algorytmu genetycznego}
\label{fig:alg_gen}
\end{figure}

\subsubsection{Uczenie maszynowe}
\label{sub:uczenie_maszynowe}
\textbf{Uczenie maszynowe} to dziedzina informatyki mocno powiązana ze sztuczną inteligencją. Uczenie maszynowe zajmuje się projektowaniem i konstrukcją algorytmów i systemów, których potrafią się ucyzć (zdobywać wiedzę) z uzyskanych danych.

Algorytmy uczenia maszynowego można podzielić na dwa rodzaje: nadzorowane i nienadzorowane. Algorytmy nadzorowane na wejściu dostają wzorcowy zbiór danych, który służy im za bazę do oceny bądź klasyfikacji nowych danych. Algorytmy nienadzorowane nie mają takiego zestawu danych. Przykładem algorytmu nienadzorowanego jest algorytm \textit{k-means} \cite{sugar03}.

\subsubsection{Przetwarzanie języków naturalnych}
\label{sub:nlp}
\textbf{Przetwarzanie języków naturalnych} (\textit{NLP -- Natural Language Processing}) jest przykładowym wykorzystaniem uczenia maszynowego i wiedzy z zakresu lingwistyki. Jest to zbiór technik służących do analizy języków naturalnych -- czyli takich, jakimi posługują się ludzie na co dzień. Jednym z bardziej znanych zastosowań tych algorytmów jest analiza sentymentów postów na Twitterze \cite{agarwal11}. Dane pochodzące z Twittera były też używane do estymowania aktywności wirusa świńskiej grypy H1N1 \cite{signorini11}.

\subsubsection{MapReduce}
\label{sub:mapreduce}
\textbf{MapReduce} jest to platforma stworzona przez pracowników firmy Google.  W 2004 r. dwóch z nich (Jeffrey Dean oraz Sanjay Ghemawat) wydali artykuł \cite{dean08}, w którym przedstawili nowy system. 

System ten ma za zadanie tworzenie aplikacji działających jednocześnie na tysiącach komputerów. Jak nazwa wskazuje, mamy w nim doczynienia z dwoma częściami obliczeń, a mianowicie mapowaniem (map) oraz redukcją (reduce).

Największym plusem tego podejścia jest możliwość łatwego rozdzielenia operacji na różne serwery, ponieważ można założyć, że każda operacja mapowania jest niezależna od pozostałych.

\subsubsection{Statystyka}
\label{sub:statystyka}
\textbf{Statystyka} jest nauką matematyczną zajmującą się zbieranem, organizjacją, analizą i interpretacją, a także prezentacją danych \cite{statystyka:podrecznik}. Metody statystyczne są często używane do znajdywania i określania związków w zestawach danych. Przykładem metody statystycznej są testy A/B opisane w sekcji \ref{sub:a/b_testing}.

\subsubsection{Przetwarzanie sygnałów}
\label{sub:przetwarzanie_sygnalow}
\textbf{Przetwarzanie sygnałów} jest nauką zajmującą się analizą i interpretacją sygnałów, analogowych bądź cyfrowych \cite{smith97}, takich jak sygnału radiowe, audio, czy obrazki.

\subsubsection{Symulacja}
\label{sub:symulacja}
,,\textbf{Symulacja} to technika służąca do imitowania działania całego systemu lub też tylko naśladowania pewnej sytuacji (ekonomicznej, militarnej, mechanicznej, etc.) poprzez użycie odpowiednich modeli lub urządzeń w celu zdobycia informacji, czy też w celach dydaktycznych'' \cite{www:symulacja}.

Technika symulacji jest najpopularniejsza tam, gdzie analityczne dojście do rozwiązania byłoby niemożliwe, lub prowadziłoby do dużych nakładów finansowych lub czasowych.

Symulacje \textit{Monte-Carlo} są klasą algorytmów symulacji, polegającą na wykonywaniu tysięcy symulacji z różnymi, losowymi parametrami, aby uzyskać histogram rozkładu prawdopodobieństwa \cite{math:monte-carlo}.

Do przeprowadzania symulacji komputerowej stosuje się narzędzia takie jak SciLab \cite{www:scilab}, język programowania GPSS \cite{www:gpss} oraz @Risk \cite{www:risk}.

\subsubsection{Szereg czasowy}
\label{sub:szereg_czasowy}
\textbf{Szereg czasowy} to ciąg obserwacji pewnego zjawiska w kolejnych jednostlach czasu. Analiza szeregów czasowych uzywa technik mających źródła w statystyce, jak i w przetwarzaniu sygnałów.

\subsubsection{Wizualizacja}
\label{sub:wizualizacja}
Techniki \textbf{wizualizacji} naukowej są używane do tworzenia obrazków, diagramów, wykresów bądź animacji, których zadaniem jest ułatwienie zrozumienia i przekzazanie pewnych wniosków wynikających z analizy danych \cite{lawrence1994}. Do tworzenia prostych wykresów i diagramów często używa się takiego oprogramowania jak R \cite{www:R} bądź Octave \cite{www:octave}.

\subsection{Implementacje}
% TODO

\subsection{Big Data wg Google}
\label{ssub:google}
System Big Data Google'a składa się z kilku elementów, m.in. rozproszonego systemu plików, bazy danych NoSQL, architektury MapReduce.

\subsubsection{GFS}
\label{ssub:gfs}
\textbf{GFS} (\textit{Google File System}) jest rozproszonym systemem plików uzywanym przez Google'a na swoich serwerach, opisanym w \cite{ghemawat03}. GFS jest zoptymalizowany do przechowywania olbrzymich ilości danych, generowanych przez usługi Google'a, głównie wyszukiwarkę. W przeciwieństwie do większości systemów plików, GFS nie jest zaimplementowany w jądrze systemu, tylko jako zwyczajna biblioteka.

W klastrze GFS występują dwa typy serwerów:
\begin{itemize}
    \item \textbf{Master} -- tylko jeden w danym systemie
    \item \textbf{Chunk Server} -- może ich być wiele
\end{itemize}
Każdy plik w systemie jest dzielony na bloki (wielkości 64MB), identyfikowane64-bitowym kluczem. Bloki te są przechowywane na \textit{Chunk Server}ach. Każdy taki blok jest replikowany kilka razy w klastrze.
Serwer \textit{Master} nie przechowuje samych bloków, lecz tylko metadane z nimi związane, takie jak mapowanie kluczy na lokacje bloków i ich kopii, jakie bloki składają się na jakie pliki, etc.
Dostęp do danych działa w następujący sposób:
\begin{enumerate}
    \item Aplikacja pyta serwera \textit{Master} o lokację żądanego bloku
    \item Jeśli na danym bloku nie są przeprowadzane żadne operacje, \textit{Master} zwraca adres do bloku
    \item Aplikacja modyfikuje dane bezpośrednio na \textit{Chunk server}ze wskazanym przez adres podanym przez serwer główny.
\end{enumerate}

Przykładowa infrastruktura klastra GFS ukazana jest na obrazku \ref{fig:google:gfs}.

\begin{figure}
    \centering
    \includegraphics[scale=0.2]{obrazki/GoogleFileSystemGFS.png}
    \caption{Google File System -- infrastruktura}
    \label{fig:google:gfs}
\end{figure}

\subsubsection{BigTable}
\label{ssub:bigtable}
\textbf{BigTable} jest bazą danych NoSQL używaną przez Google. 

BigTable jest rzadką, rozproszoną mapą, indeksowaną za pomocą dwóch ciągów znakowych (wiersza i kolumny) oraz 64-bitowej daty. Każda wartość w mapie jest po prostu tablicą bajtów
$$(row: \texttt{string} \times column: \texttt{string} \times timestamp: \texttt{int64}) \mapsto \texttt{string}$$
Tabelki BigTable są optymalizowane do użytku pod GFS poprzez podział na \textit{tablety} -- segmenty tabelki podzielone wzdłuż wiersza.

Schemat struktury tabelki BigTable zaprezentowany jest na rysunku \ref{fig:google:big-table}.

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{obrazki/big-table.png}
    \caption{BigTable -- struktura}
    \label{fig:google:big-table}
\end{figure}

\subsubsection{MapReduce}
\label{ssub:mapreduce}
\textbf{MapReduce} jest modelem programowania, stworzonym przez Google i opisanym w \cite{dean08}. Model ten jest używany wraz z wspomnianymi wcześniej BigTable i GFS do analizy gigantycznych ilości danych w Google.

\subsubsection{BigQuery}
\label{ssub:bigquery}
Google \textbf{BigQuery} jest usługą umozliwiającą osobom trzecim skorzystanie z infrastruktury Google do analizy Big Data \cite{www:google-big-query}.

\subsection{Hadoop}
\label{ssub:hadoop}
Apache Hadoop jest otwartą (open source) platformą implementującą paradygmat MapReduce \cite{dean08}, które wyprodukowało Google. Jego autorem jest Doug Cutting.

\subsubsection{Historia}
\label{ssub:hadoop_historia}
Projekt o nazwie Hadoop rozpoczęto w 2005 r. Jego tworzenie trwało stosunkowo długo, ponieważ dopiero  w 2011 r. opublikowano pierwszą wersję - Hadoop 1.0. Produkt ten od początku był tworzony jako platforma mająca na celu obsługę bardzo dużych zbiorów danych. 

\subsubsection{Ogólne działanie}
\label{ssub:ogolne_dzialanie}
Ogólną myślą Hadoop jest podzielenie dużych zbiorów danych na mniejsze, przetwarzane równolegle w węzłach wykorzystujących serwery. Wielką zaletą tej platformy jest niezależność od systemu operacyjnego oraz oczywiście wspomniana już wcześniej możliwość obsługi danych niestrukturyzowanych.

Wykorzystując narzędzia Apache Flume oraz Apache Sqoop, odpowiednio służących do wymiany danych między systemami RDBMS i Hadoop oraz przekierowanie logów systemowych do Hadoop w czasie rzeczywistym, możliwe jest zintegrowanie już stworzonego systemu razem z platformą Hadoop. Zaletą tego podejścia jest możliwość pracy z danymi niezależnie od ich wielkości. Wraz z powiększeniem się ilości danych należy tylko dodać nowe węzły Hadoop oraz serwery, które przetwarzają dane.

\subsubsection{Apache Hadoop}
\label{ssub:apache_hadoop}
Apache Hadoop jest open-sourcowym oraz skalowalnym oprogramowaniem. Jest to framework pozwalajócy na przetwarzanie bardzo dużych zbiorów danych z różnych komputerów używajóc prostego modelu programowania. Umożliwia on pracę z tysiócami obliczeniowo niezależnymi komputerami oraz petabajtami danych. Hadoop pochodzi z MapReduce oraz Google File System.

\subsubsection{Hadoop Distributed File System}
\label{ssub:hdfs}
Hadoop Distributed File System (HDFS) jest rozproszonym systemem plików zapewniajócym odporność na uszkodzenia. HDFS zapewnia dostęp o wysokiej przepustowości do danych aplikacji oraz nadaje się do obsługi aplikacji, które posiadajó duże zbiory danych. Hadoop zapewnia system plików, które mogó przechowywać dane na tysiócach serwerów i pracuje w oparciu o system MapReduce. Duże dane automatycznie dzielone só na mniejsze kawałki, które mogó być przetwarzane przez różne węzły klastra hadoop.

Obrazek \ref{fig:rozklad_danych} przedstawia rozkład danych w węzłach w czasie ładowania.

\begin{figure}[h]
\centerline{\includegraphics[scale=0.5]{obrazki/rozklad_danych.png}}
\caption{Schemat działania algorytmu genetycznego}
\label{fig:rozklad_danych}
\end{figure}

\subsubsection{Architektura HDFS}
\label{ssub:hdfs_architecture}
Na rysunku \ref{fig:hdfs_architecture} pokazano architekturę HDFS. Można na nim zobaczyć, że klaster HDFS składa się z pojedynczego NameNode'a (serwer główny), który odpowiedzialny jest za zarządzanie przestrzenią nazw oraz regulacją dostępności plików przez klientów. Ponadto występuje również pewna liczba DataNode'ów (węzłów danych), zwykle jeden na każdy węzeł w klastrze, które zarządzają pamięcią dołączoną do węzłów, które działają. HDFS pokazuje przestrzeń nazw systemu plików i pozwala na przechowywanie danych użytkownika w plikach. Plik podzielony jest na jeden lub więcej bloków, które przechowywane są w węzle danych. Serwer główny (NameNode) mapuje bloki do węzłów danych.
HDFS zaprojektowany jest tak, aby bardzo duże pliki przechowywane były przez maszyny w dużych klastrach. Przechowuje on  każdy plik jako ciąg bloków

\begin{figure}[h]
\centerline{\includegraphics[scale=0.5]{obrazki/HDFS_architecture.png}}
\caption{Architektura HDFS}
\label{fig:hdfs_architecture}
\end{figure}

\subsubsection{Wysokkopoziomowa architektura HDFS}
\label{ssub:hdfs_high_level_architecture}
Klaster Hadoop składa się z jednego węzła ,,mistrza'' (master) i wielu węzłów ,,niewolników'' (slaves). JobTracker jest serwisem wewnątrz Hadoop, który ,,dzierżawi'' zadania MapReduce dla konkretnych węzłów w klastrze. Najlepiej jakby to były węzły, które zawierają dane, a ewentualnie są na tej samej półce.

TaskTracker jest węzłem w klastrze, który akceptuje zadania mapowania, redukcji oraz przetasowania z JobTrackera. Węzeł główny składa się z JobTrackera, TaskTrackera, NameNode'a oraz DataNode'a. Węzeł podrzędny (niewolnik) działa zarówno jako DataNode oraz TaskTracker.ś

Wszytko to zobrazowane jest na rysunku \ref{fig:hdfs_hight_level_architecture}.

\begin{figure}[h]
\centerline{\includegraphics[scale=0.5]{obrazki/wysokopoziomowa_architektura_hadoop.png}}
\caption{Wysokopoziomowa architektura HDFS}
\label{fig:hdfs_hight_level_architecture}
\end{figure}


\subsubsection{Porównanie do relacyjnych baz danych}
\label{ssub:porownanie_z_relacyjnymi}
Platforma ta jest wspomagana przez stworzony przez firmę Google framework programistyczny MapReduce (opisany po krótce w sekcji \ref{sub:mapreduce}), który w znacznym stopniu ułatwia tworzenie narzędzi do analizy informacji. Jego przewagą nad relacyjnymi bazami danych jest to, że od samego początku jest przystosowany do zarządzania bazami przechowywującymi dane niestrukturalne.

Platforma Hadoop nie ma na calu zastąpienie obecną infrastrukturę baz danych, a jedynie zwiększenie efektywności zarządzania pamięcią masową oraz wszelkiego rodzaju danymi.

Większość firm korzystających z platformy Hadoop, używa je razem z relacyjnymi bazami danych. Zazwyczaj platforma ta służy do obrabiania wielkich danych, z którymi mogą sobie poradzić relacyjne bazy danych.


\subsection{Zastosowania implementacji}
%TODO

%TODO trendy itp.

% section Analiza literatury (end)
